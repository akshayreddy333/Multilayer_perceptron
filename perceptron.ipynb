{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Perceptron\n",
    "**Name: Akshay Reddy Akkati**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data file to dataframe\n",
    "df = pd.read_csv(\"mnist_data.txt\", header=None, delimiter=r\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting bias term\n",
    "# df['']=1\n",
    "df.insert(loc=784, column=784,value=1,allow_duplicates=False)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading labels\n",
    "labels = pd.read_csv(\"mnist_labels.txt\", header=None)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data to train and test (into halves)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing weight vector with default values as zeros\n",
    "weight_vector=pd.DataFrame(index=np.arange(10), columns=np.arange(785)).fillna(0)\n",
    "# print(weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies after iteration: 0\n",
      "training:0.8278\n",
      "testing:0.8144\n",
      "Accuracies after iteration: 1\n",
      "training:0.8332\n",
      "testing:0.8152\n",
      "Accuracies after iteration: 2\n",
      "training:0.8332\n",
      "testing:0.809\n",
      "Accuracies after iteration: 3\n",
      "training:0.9128\n",
      "testing:0.881\n",
      "Accuracies after iteration: 4\n",
      "training:0.8806\n",
      "testing:0.8452\n",
      "Accuracies after iteration: 5\n",
      "training:0.8868\n",
      "testing:0.8446\n",
      "Accuracies after iteration: 6\n",
      "training:0.9094\n",
      "testing:0.8698\n",
      "Accuracies after iteration: 7\n",
      "training:0.9024\n",
      "testing:0.8606\n",
      "Accuracies after iteration: 8\n",
      "training:0.8964\n",
      "testing:0.8508\n",
      "Accuracies after iteration: 9\n",
      "training:0.921\n",
      "testing:0.879\n",
      "The accuracy of the classifier on the training set: 92.10000000000001%\n",
      "The accuracy of the classifier on the test set: 87.9%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Number of iterations for outer loop\n",
    "num_of_iterations=10\n",
    "for itr in range(num_of_iterations):\n",
    "    for i in X_train.index:\n",
    "        activation = weight_vector.dot(X_train.loc[i])\n",
    "        max_value_index = activation.idxmax()\n",
    "# When a prediction is wrong, the weights for the correct class are increased by x and the weights for the \n",
    "# incorrectly predicted class are decreased by x\n",
    "        if(max_value_index != y_train.loc[i,0]):\n",
    "            weight_vector.loc[max_value_index] = weight_vector.loc[max_value_index] - X_train.loc[i]\n",
    "            weight_vector.loc[y_train.loc[i,0]] = weight_vector.loc[y_train.loc[i,0]] + X_train.loc[i]\n",
    "            \n",
    "# defining dataframes for train and test predictions\n",
    "    y_train_predict=pd.DataFrame(index=list(y_train.index),columns=np.arange(1)).fillna(0)\n",
    "    y_test_predict=pd.DataFrame(index=list(y_test.index),columns=np.arange(1)).fillna(0)\n",
    "    \n",
    "# Filling the prediction dataframes of training and testing\n",
    "    for i in X_train.index:\n",
    "        y_train_predict.loc[i,0]=(weight_vector.dot(X_train.loc[i])).idxmax()    \n",
    "\n",
    "    for i in X_test.index:\n",
    "        y_test_predict.loc[i,0]=(weight_vector.dot(X_test.loc[i])).idxmax()\n",
    "\n",
    "# Calculating accuracies\n",
    "    train_acc=accuracy_score(y_train,y_train_predict)\n",
    "    test_acc=accuracy_score(y_test,y_test_predict)\n",
    "    print('Accuracies after iteration: ' + str(itr))\n",
    "    print('training:' +str(train_acc))\n",
    "    print('testing:' + str(test_acc))\n",
    "print('The accuracy of the classifier on the training set: ' + str(train_acc*100) + '%')\n",
    "print('The accuracy of the classifier on the test set: ' + str(test_acc*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation and Convergence criterion\n",
    "**Loading data**\n",
    "* We have MNIST digits dataset\n",
    "* Each row in the data file is 784 integers that represent the grayscale values of a 28x28 handwritten digit. Each row in the labels file is a single digit in the range 0-9 and is in a 1-to-1 correspondence with rows in the data file.\n",
    "* Initially load the data from given text files to the dataframes\n",
    "* I have used python pandas libraries for doing that\\\n",
    "**Including bias term**\n",
    "* I inserted a bias term in the dataframe of data (added extra column) with value '1'.\\\n",
    "**Splitting the data**\n",
    "* I have to split the data and labels randomly into halves as X_train, X_test, y_train, y_test\\\n",
    "**Weight vector**\n",
    "* Construct weight vector of size 10 rows (since 10 class labels) and 785 columns and initialize values to zeros\\\n",
    "**Running the Perceptron**\n",
    "* First calculate the dot product of weight vector and X_train and find the index value of the greatest value.\n",
    "* Now compare the index of maximum value in weight vector with the corresponding value in labels.\n",
    "* When a prediction is wrong, the weights for the correct class are increased by x and the weights for the incorrectly predicted class are decreased by x\n",
    "* We stop the application till we reach the convergence, This convergence can be choosen in different ways. One is till we reach greater accuracy and other is choosing some arbitrary number of iterations.\n",
    "* I have used some arbitrary number of iterations for reaching the convergence\\\n",
    "**Testing accuracy**\n",
    "* I have defined two dataframes for train and test predicted labels.\n",
    "* Compared them with the actual labels and finally printed the accuracy.\n",
    "* In the above code shown, I have displayed accuracies for 10 iterations.\n",
    "* My final accuracies obtained after 100 iterations are: train: **98.84%** test: **87.08%**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
